{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q1: Write a python program to scrape data for “Data Analyst” Job position in \n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” \n",
    "in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>(850 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hiring Data Analysts For E commerce Platform |...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>(201 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>DA - Urgent Opening For Data Analyst BFSI Doma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>(620 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12-18 Yrs</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Assistant Vice President - MIS &amp; Reporting ( B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>(94 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_required                             company_name  \\\n",
       "0             0-3 Yrs       Inflexion Analytix Private Limited   \n",
       "1             0-2 Yrs  GlaxoSmithKline Pharmaceuticals Limited   \n",
       "2             0-5 Yrs                            (850 Reviews)   \n",
       "3             5-8 Yrs         Allegis Services India Pvt. Ltd.   \n",
       "4            7-10 Yrs                            (201 Reviews)   \n",
       "5             4-9 Yrs      Shell India Markets Private Limited   \n",
       "6             5-8 Yrs                            (620 Reviews)   \n",
       "7           12-18 Yrs                        Applied Materials   \n",
       "8             3-6 Yrs                             (94 Reviews)   \n",
       "9             3-6 Yrs           Tata Consultancy Services Ltd.   \n",
       "\n",
       "                                        job_location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                        Mumbai, Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                           job_title  \n",
       "0    Data Scientist / Data Analyst -Business Analyst  \n",
       "1                                       Data Analyst  \n",
       "2  Hiring Data Analysts For E commerce Platform |...  \n",
       "3                                       Data Analyst  \n",
       "4                                       Data Analyst  \n",
       "5  DA - Urgent Opening For Data Analyst BFSI Doma...  \n",
       "6                                       Data Analyst  \n",
       "7  Assistant Vice President - MIS & Reporting ( B...  \n",
       "8                                       Data Analyst  \n",
       "9                                       Data Analyst  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "\n",
    "# entering “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\") #job search bar\n",
    "search_field_location=driver.find_element_by_id('qsb-location-sugg') #location search bar\n",
    "search_field_designation.send_keys(\"Data Analyst\")\n",
    "search_field_location.send_keys(\"Bangalore\")\n",
    "\n",
    "\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "\n",
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "\n",
    "time.sleep(4)\n",
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "        \n",
    "time.sleep(4)        \n",
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:2]\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "#scraping the experience_required \n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "# creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_title\":job_title[0:10]})\n",
    "df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q2: Write a python program to scrape data for “Data Scientist” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter\n",
    "“Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Job Role : Data Scientist/Data Analyst /Busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior / Lead Data Scientist</td>\n",
       "      <td>TVS CREDIT SERVICES LIMITED</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Key Responsibilities\\nBe responsible for scali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>(779 Reviews)</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Roles and Responsibilities\\n\\nMandatory Skills...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Roles and Responsibilities\\n\\nMandatory Skills...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Analytics &amp; AI Product Mgmt - Sr. Data Scientist</td>\n",
       "      <td>(85 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>.\\nRoles and Responsibilities\\nAnalyze structu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist, Modeling</td>\n",
       "      <td>(85 Reviews)</td>\n",
       "      <td>Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...</td>\n",
       "      <td>We wont say we can predict the future, but our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>(850 Reviews)</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Vijaya Management Services</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                       Senior / Lead Data Scientist   \n",
       "2  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "3  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "4   Analytics & AI Product Mgmt - Sr. Data Scientist   \n",
       "5                              Senior Data Scientist   \n",
       "6                    Senior Data Scientist, Modeling   \n",
       "7                        Data Scientist - IBM Garage   \n",
       "8                                     Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                              company_name  \\\n",
       "0       Inflexion Analytix Private Limited   \n",
       "1              TVS CREDIT SERVICES LIMITED   \n",
       "2                            (779 Reviews)   \n",
       "3                                 CES Ltd.   \n",
       "4                             (85 Reviews)   \n",
       "5                                 CES Ltd.   \n",
       "6                             (85 Reviews)   \n",
       "7  GlaxoSmithKline Pharmaceuticals Limited   \n",
       "8                            (850 Reviews)   \n",
       "9               Vijaya Management Services   \n",
       "\n",
       "                                        job_location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                 Pune, Chennai, Bangalore/Bengaluru   \n",
       "2  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "3  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                 Pune, Chennai, Bangalore/Bengaluru   \n",
       "6  Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...   \n",
       "7  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "8  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "9  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "\n",
       "                                     job_description  \n",
       "0  Job Role : Data Scientist/Data Analyst /Busine...  \n",
       "1  Key Responsibilities\\nBe responsible for scali...  \n",
       "2  Roles and Responsibilities\\n\\nMandatory Skills...  \n",
       "3  Roles and Responsibilities\\n\\nMandatory Skills...  \n",
       "4                                                ---  \n",
       "5  .\\nRoles and Responsibilities\\nAnalyze structu...  \n",
       "6  We wont say we can predict the future, but our...  \n",
       "7                                                ---  \n",
       "8                                                ---  \n",
       "9                                                ---  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "\n",
    "# entering “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")   #job search bar\n",
    "search_field_location=driver.find_element_by_id('qsb-location-sugg')  #location search bar\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "search_field_location.send_keys(\"Bangalore\")\n",
    "\n",
    "\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "full_job_description=[]\n",
    "\n",
    "\n",
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "\n",
    "time.sleep(4)\n",
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "        \n",
    "time.sleep(4)        \n",
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "\n",
    "# scraping the full job-description, for scraping full job description we have to go in each of the jobs separately\n",
    "urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")]\n",
    "for url in urls[0:10]:\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//section[@class='job-desc']/div[1]\").text\n",
    "        description=raw_description.replace(\"Contact Person\",\"@@@@@\")\n",
    "        description= description.split(\"@@@@@\")\n",
    "        full_job_description.append(description[0])\n",
    "    except NoSuchElementException :\n",
    "        full_job_description.append(\"---\")\n",
    "        \n",
    "        \n",
    " # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"job_title\":job_title[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_description\":full_job_description[0:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q3: In this question you have to scrape data using the filters available on the\n",
    "webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name,\n",
    "experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist II 5+ yrs II Gurgaon</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>(9623 Reviews)</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent opportunity For Data Scientist</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Zenatix Solutions Private Limited</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>(14 Reviews)</td>\n",
       "      <td>New Delhi, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>(12 Reviews)</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Noida/ B'lore</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Mobikwik</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>(104 Reviews)</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title experience_required  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst             0-3 Yrs   \n",
       "1                                     Data Scientist             4-9 Yrs   \n",
       "2         Senior Data Scientist II 5+ yrs II Gurgaon            5-10 Yrs   \n",
       "3           Excellent opportunity For Data Scientist             3-7 Yrs   \n",
       "4                                     Data Scientist             3-5 Yrs   \n",
       "5           DATA Scientist – Gurgaon (Exp 3-6 years)             3-6 Yrs   \n",
       "6           DATA Scientist – Gurgaon (Exp 3-6 years)             3-6 Yrs   \n",
       "7                     Data Scientist - Noida/ B'lore             3-8 Yrs   \n",
       "8  Only Fresher / Data Scientist / Data Analyst /...             0-5 Yrs   \n",
       "9                                     Data Scientist             5-8 Yrs   \n",
       "\n",
       "                                        company_name  \\\n",
       "0                 Inflexion Analytix Private Limited   \n",
       "1                             IBM India Pvt. Limited   \n",
       "2                                     (9623 Reviews)   \n",
       "3                  Zenatix Solutions Private Limited   \n",
       "4                                       (14 Reviews)   \n",
       "5              NEC CORPORATION INDIA PRIVATE LIMITED   \n",
       "6                                       (12 Reviews)   \n",
       "7                                           Mobikwik   \n",
       "8                                      (104 Reviews)   \n",
       "9  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...   \n",
       "\n",
       "                                        job_location  \n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  \n",
       "1  Noida, Hyderabad/Secunderabad, Bangalore/Benga...  \n",
       "2                                   Gurgaon/Gurugram  \n",
       "3                         Noida, Bangalore/Bengaluru  \n",
       "4           New Delhi, Gurgaon/Gurugram, Delhi / NCR  \n",
       "5                      Gurgaon/Gurugram, Delhi / NCR  \n",
       "6                      Gurgaon/Gurugram, Delhi / NCR  \n",
       "7                         Noida, Bangalore/Bengaluru  \n",
       "8               Noida, Gurgaon/Gurugram, Delhi / NCR  \n",
       "9  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "\n",
    "# entering “Data Scientist” in “Skill,Designations,Companies” field\n",
    "\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")   #job  search bar\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "# creating empty lists for scraping data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "#finding the delhi/ncr check box\n",
    "loc=driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]/label/p\")\n",
    "loc.click()\n",
    "\n",
    "time.sleep(2)\n",
    "# finding the salary check box\n",
    "slry_box = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[2]/label/p\")\n",
    "slry_box.click()\n",
    "\n",
    "time.sleep(3)\n",
    "#scraping the job-titles\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    "#scraping the job-location\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    "#scraping the company_name \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    "#scraping the experience_required \n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "            \n",
    "time.sleep(3)            \n",
    " # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"job_title\":job_title[0:10],\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\n",
    "                 \"job_location\":job_location[0:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist\n",
    "Designation in Noida location. You have to scrape company_name, No. of days\n",
    "ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida”\n",
    "in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown\n",
    "page.\n",
    "WEB SCRAPING ASSIGNMENT-2\n",
    ".\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Enter your login credentials in the chrome window opened by webdriver. Do this step manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_ratings</th>\n",
       "      <th>days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adobe</td>\n",
       "      <td>4.4</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>3.8</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>3.6</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDFC Bank</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>4.2</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SearchUrCollege</td>\n",
       "      <td>3.8</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xtLytics</td>\n",
       "      <td>4.1</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Unyscape Infocom Pvt. Ltd</td>\n",
       "      <td>4.1</td>\n",
       "      <td>29d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   company_name company_ratings days_ago\n",
       "0                      Ericsson             4.1       5d\n",
       "1                         Adobe             4.4     30d+\n",
       "2                Biz2Credit Inc             3.8     30d+\n",
       "3  Salasar New Age Technologies             3.6     30d+\n",
       "4                     HDFC Bank             5.0     30d+\n",
       "5                      Techlive             3.0     30d+\n",
       "6  Salasar New Age Technologies             4.2     30d+\n",
       "7               SearchUrCollege             3.8     30d+\n",
       "8                      xtLytics             4.1     30d+\n",
       "9     Unyscape Infocom Pvt. Ltd             4.1      29d"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now entering “Data Scientist” in “SJob Title, Keywords or Company” field and enter “Noida” in “location” field.\n",
    "\n",
    "search_field_designation=driver.find_element_by_xpath(\"//div[@class='d-flex flex-row align-items-center']//div[1]//div[1]//input\")  #job search bar\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "time.sleep(2)\n",
    "search_field_location=driver.find_element_by_xpath(\"//div[@class='d-flex flex-row align-items-center']//div[3]//div[1]//input\")  #location search bar\n",
    "search_field_location.clear()   # clearing job location search_bar\n",
    "search_field_location.send_keys(\"Noida\")\n",
    "\n",
    "time.sleep(2)\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "# creating empty lists for scraping data\n",
    "company_ratings=[]\n",
    "company_name=[]\n",
    "days_ago=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "# finding the element where company name is present\n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "\n",
    "        \n",
    "time.sleep(3)        \n",
    "# finding the element where ratings of the company  is present\n",
    "ratings=driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\")\n",
    "for i in ratings:\n",
    "    if i.text is None :\n",
    "        company_ratings.append(\"--\") \n",
    "    else:\n",
    "        company_ratings.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    "# finding the element where  No. of days ago when job was posted is present\n",
    "days=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "for i in days:\n",
    "    if i.text is None :\n",
    "        days_ago.append(\"--\") \n",
    "    else:\n",
    "        days_ago.append(i.text)\n",
    "        \n",
    "        \n",
    "time.sleep(3)        \n",
    " # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "df=pd.DataFrame({\"company_name\":company_name[0:10],\"company_ratings\":company_ratings[0:10],\"days_ago\":days_ago[0:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q5: Write a python program to scrape the salary data for Data Scientist designation\n",
    "in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min\n",
    "salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page\n",
    "You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company\n",
    "name, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Enter your login credentials in the chrome window opened by webdriver. Do this step manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>min_salaries</th>\n",
       "      <th>max_salaries</th>\n",
       "      <th>average_salaries</th>\n",
       "      <th>no_of_salaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹169K</td>\n",
       "      <td>₹2,500K</td>\n",
       "      <td>₹ 6,29,287</td>\n",
       "      <td>116 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹282K</td>\n",
       "      <td>₹3,650K</td>\n",
       "      <td>₹ 10,25,234</td>\n",
       "      <td>103 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mu Sigma</td>\n",
       "      <td>₹289K</td>\n",
       "      <td>₹4,586K</td>\n",
       "      <td>₹ 5,93,426</td>\n",
       "      <td>87 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>₹334K</td>\n",
       "      <td>₹1,845K</td>\n",
       "      <td>₹ 8,44,087</td>\n",
       "      <td>54 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹180K</td>\n",
       "      <td>₹3,000K</td>\n",
       "      <td>₹ 9,69,165</td>\n",
       "      <td>53 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>₹213K</td>\n",
       "      <td>₹3,129K</td>\n",
       "      <td>₹ 8,10,985</td>\n",
       "      <td>44 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fractal</td>\n",
       "      <td>₹587K</td>\n",
       "      <td>₹2,049K</td>\n",
       "      <td>₹ 14,72,159</td>\n",
       "      <td>40 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Capgemini</td>\n",
       "      <td>₹347K</td>\n",
       "      <td>₹1,762K</td>\n",
       "      <td>₹ 8,95,952</td>\n",
       "      <td>34 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>₹587K</td>\n",
       "      <td>₹3,279K</td>\n",
       "      <td>₹ 14,47,627</td>\n",
       "      <td>29 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Impact Analytics</td>\n",
       "      <td>₹504K</td>\n",
       "      <td>₹900K</td>\n",
       "      <td>₹ 6,46,795</td>\n",
       "      <td>28 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹350K</td>\n",
       "      <td>₹3,000K</td>\n",
       "      <td>₹ 9,26,569</td>\n",
       "      <td>27 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>₹230K</td>\n",
       "      <td>₹3,250K</td>\n",
       "      <td>₹ 16,20,190</td>\n",
       "      <td>26 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wipro</td>\n",
       "      <td>₹347K</td>\n",
       "      <td>₹1,537K</td>\n",
       "      <td>₹ 8,94,763</td>\n",
       "      <td>25 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jio</td>\n",
       "      <td>₹314K</td>\n",
       "      <td>₹2,219K</td>\n",
       "      <td>₹ 12,50,277</td>\n",
       "      <td>22 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Deloitte</td>\n",
       "      <td>₹178K</td>\n",
       "      <td>₹2,100K</td>\n",
       "      <td>₹ 11,81,000</td>\n",
       "      <td>19 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>₹382K</td>\n",
       "      <td>₹2,240K</td>\n",
       "      <td>₹ 7,22,644</td>\n",
       "      <td>19 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹196K</td>\n",
       "      <td>₹2,178K</td>\n",
       "      <td>₹ 11,74,242</td>\n",
       "      <td>19 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Google</td>\n",
       "      <td>₹264K</td>\n",
       "      <td>₹7,179K</td>\n",
       "      <td>₹ 14,08,244</td>\n",
       "      <td>18 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cyient</td>\n",
       "      <td>₹110K</td>\n",
       "      <td>₹1,926K</td>\n",
       "      <td>₹ 9,67,483</td>\n",
       "      <td>18 salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Anheuser-Busch InBev</td>\n",
       "      <td>₹1,268K</td>\n",
       "      <td>₹1,900K</td>\n",
       "      <td>₹ 15,75,878</td>\n",
       "      <td>17 salaries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      company_name min_salaries max_salaries average_salaries  \\\n",
       "0        Tata Consultancy Services        ₹169K      ₹2,500K       ₹ 6,29,287   \n",
       "1                              IBM        ₹282K      ₹3,650K      ₹ 10,25,234   \n",
       "2                         Mu Sigma        ₹289K      ₹4,586K       ₹ 5,93,426   \n",
       "3   Cognizant Technology Solutions        ₹334K      ₹1,845K       ₹ 8,44,087   \n",
       "4                        Accenture        ₹180K      ₹3,000K       ₹ 9,69,165   \n",
       "5                          Infosys        ₹213K      ₹3,129K       ₹ 8,10,985   \n",
       "6                          Fractal        ₹587K      ₹2,049K      ₹ 14,72,159   \n",
       "7                        Capgemini        ₹347K      ₹1,762K       ₹ 8,95,952   \n",
       "8                           Amazon        ₹587K      ₹3,279K      ₹ 14,47,627   \n",
       "9                 Impact Analytics        ₹504K        ₹900K       ₹ 6,46,795   \n",
       "10              Ericsson-Worldwide        ₹350K      ₹3,000K       ₹ 9,26,569   \n",
       "11                       Microsoft        ₹230K      ₹3,250K      ₹ 16,20,190   \n",
       "12                           Wipro        ₹347K      ₹1,537K       ₹ 8,94,763   \n",
       "13                             Jio        ₹314K      ₹2,219K      ₹ 12,50,277   \n",
       "14                        Deloitte        ₹178K      ₹2,100K      ₹ 11,81,000   \n",
       "15                   Tech Mahindra        ₹382K      ₹2,240K       ₹ 7,22,644   \n",
       "16                   ZS Associates        ₹196K      ₹2,178K      ₹ 11,74,242   \n",
       "17                          Google        ₹264K      ₹7,179K      ₹ 14,08,244   \n",
       "18                          Cyient        ₹110K      ₹1,926K       ₹ 9,67,483   \n",
       "19            Anheuser-Busch InBev      ₹1,268K      ₹1,900K      ₹ 15,75,878   \n",
       "\n",
       "   no_of_salaries  \n",
       "0    116 salaries  \n",
       "1    103 salaries  \n",
       "2     87 salaries  \n",
       "3     54 salaries  \n",
       "4     53 salaries  \n",
       "5     44 salaries  \n",
       "6     40 salaries  \n",
       "7     34 salaries  \n",
       "8     29 salaries  \n",
       "9     28 salaries  \n",
       "10    27 salaries  \n",
       "11    26 salaries  \n",
       "12    25 salaries  \n",
       "13    22 salaries  \n",
       "14    19 salaries  \n",
       "15    19 salaries  \n",
       "16    19 salaries  \n",
       "17    18 salaries  \n",
       "18    18 salaries  \n",
       "19    17 salaries  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now entering “Data Scientist” in “SJob Title, Keywords or Company” field and enter “Noida” in “location” field.\n",
    "\n",
    "search_field_designation=driver.find_element_by_xpath(\"//div[@class='d-flex flex-row align-items-center']//div[1]//div[1]//input\")  #job search bar\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "time.sleep(2)\n",
    "# clearing job location search_bar\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "for i in range(9):\n",
    "    driver.find_element_by_xpath(\"//div[@class='d-flex flex-row align-items-center']//div[3]//div[1]//input\").send_keys(Keys.BACK_SPACE)\n",
    "\n",
    "#location search bar\n",
    "search_field_location=driver.find_element_by_xpath(\"//div[@class='d-flex flex-row align-items-center']//div[3]//div[1]//input\")  \n",
    "search_field_location.send_keys(\"Noida\")\n",
    "\n",
    "time.sleep(2)\n",
    "# Select salary option\n",
    "option = driver.find_element_by_xpath(\"//div[@class='selectedLabel']\")\n",
    "option.click()\n",
    "time.sleep(2)\n",
    "salary_option = driver.find_element_by_xpath(\"//div[@class='dropDownOptionsContainer']//ul//li[3]\")\n",
    "salary_option.click()\n",
    "\n",
    "time.sleep(2)\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "search_button.click()\n",
    "\n",
    "# creating empty lists for scraping data\n",
    "company_name=[]\n",
    "min_salaries=[]\n",
    "max_salaries=[]\n",
    "average_salaries=[]\n",
    "no_of_salaries=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "# finding the element where company_name   is present\n",
    "company=driver.find_elements_by_xpath(\"//div[@data-test='job-info']/p[2]\")\n",
    "for i in company:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\")      \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "        \n",
    "time.sleep(3)        \n",
    "# finding the element where min salary is present\n",
    "min_salary = driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']//span[1]\")\n",
    "for i in min_salary:\n",
    "    if i.text is None:\n",
    "        min_salaries.append(\"--\")\n",
    "    else:\n",
    "        min_salaries.append(i.text)\n",
    "        \n",
    "time.sleep(3)        \n",
    "# finding the element where max salary is present\n",
    "max_salary=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[2]\")\n",
    "for i in max_salary:\n",
    "    if i.text is None :\n",
    "        max_salaries.append(\"--\") \n",
    "    else:\n",
    "        max_salaries.append(i.text)\n",
    "        \n",
    "time.sleep(3)        \n",
    "# finding the element where average salary is present\n",
    "average_salary=driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong\")\n",
    "for i in average_salary:\n",
    "    if i.text is None :\n",
    "        average_salaries.append(\"--\") \n",
    "    else:\n",
    "        average_salaries.append(i.text)\n",
    "        \n",
    "time.sleep(3)        \n",
    "# finding the element where no_of_salary is present\n",
    "no_of_salary=driver.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0 ']\")\n",
    "for i in no_of_salary:\n",
    "    if i.text is None :\n",
    "        no_of_salaries.append(\"--\") \n",
    "    else:\n",
    "        no_of_salaries.append(i.text)\n",
    "        \n",
    "        \n",
    " # creating the dataframe from the scraped data \n",
    "df=pd.DataFrame({\"company_name\":company_name,\"min_salaries\":min_salaries,\"max_salaries\":max_salaries,\n",
    "                 \"average_salaries\":average_salaries,\"no_of_salaries\":no_of_salaries})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to\n",
    "scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount \n",
    "To scrape \n",
    "the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and\n",
    "more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page\n",
    "you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of\n",
    "the page , then click on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹290</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer, Wayfarer, Wa...</td>\n",
       "      <td>₹289</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹758</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹250</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹630</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Mirrored Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹771</td>\n",
       "      <td>14% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>elegante</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹449</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Retro Square, Wayfarer Sunglasse...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)</td>\n",
       "      <td>₹337</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Over-sized Sunglasses (Free Size)</td>\n",
       "      <td>₹314</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description Price  \\\n",
       "0            NuVew              UV Protection Aviator Sunglasses (57)  ₹290   \n",
       "1   kingsunglasses  Mirrored, UV Protection Wayfarer, Wayfarer, Wa...  ₹289   \n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹758   \n",
       "3           PIRASO              UV Protection Aviator Sunglasses (54)  ₹250   \n",
       "4         Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹630   \n",
       "..             ...                                                ...   ...   \n",
       "95        Fastrack            Mirrored Aviator Sunglasses (Free Size)  ₹771   \n",
       "96        elegante              UV Protection Aviator Sunglasses (57)  ₹449   \n",
       "97       ROYAL SON  UV Protection Retro Square, Wayfarer Sunglasse...  ₹399   \n",
       "98          GANSTA         UV Protection Round Sunglasses (Free Size)  ₹337   \n",
       "99           NuVew    UV Protection Over-sized Sunglasses (Free Size)  ₹314   \n",
       "\n",
       "   Discount  \n",
       "0   68% off  \n",
       "1   80% off  \n",
       "2   15% off  \n",
       "3   84% off  \n",
       "4   21% off  \n",
       "..      ...  \n",
       "95  14% off  \n",
       "96  70% off  \n",
       "97  73% off  \n",
       "98  83% off  \n",
       "99  70% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the search bar\n",
    "search_bar=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_bar.send_keys('sunglasses')\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the button and clicking it toh search for sunglasses\n",
    "button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "button.click()\n",
    "\n",
    "\n",
    "#creating the empty list\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "#scrapping the required details\n",
    "start=0\n",
    "end=4\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    brands=driver.find_elements_by_class_name('_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    desc=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')#scraping description from the xpath\n",
    "    for i in desc:\n",
    "        description.append(i.text)#appending the description in list\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")# scraping the price from the xpath\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    disc=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")# scraping the discount from the xpath\n",
    "    for i in disc:\n",
    "        discount.append(i.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "\n",
    "time.sleep(3)        \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Brand':brand[:100],\n",
    "                'Description':description[:100],\n",
    "                'Price':price[:100],\n",
    "                'Discount':discount[:100]})\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to \n",
    "go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "you have to scrape the below mention attributes.\n",
    "These are \n",
    "1. Rating \n",
    "2. Review_summary \n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Stars</th>\n",
       "      <th>Short Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Iphone is just awesome.. battery backup is ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>It’s been almost a month since I have been usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Awesome Phone. Slightly high price but worth. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Excellent camera, good performance, no lag. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>*Review after 10 months of usage*\\nDoesn't see...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Stars        Short Review  \\\n",
       "0                5   Worth every penny   \n",
       "1                5    Perfect product!   \n",
       "2                5   Worth every penny   \n",
       "3                4        Nice product   \n",
       "4                5      Simply awesome   \n",
       "..             ...                 ...   \n",
       "95               5  Highly recommended   \n",
       "96               5    Perfect product!   \n",
       "97               5    Perfect product!   \n",
       "98               5           Fabulous!   \n",
       "99               5           Wonderful   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Best budget Iphone till date ❤️ go for it guys...  \n",
       "1   Iphone is just awesome.. battery backup is ver...  \n",
       "2   It’s been almost a month since I have been usi...  \n",
       "3   Awesome Phone. Slightly high price but worth. ...  \n",
       "4   Excellent camera, good performance, no lag. Th...  \n",
       "..                                                ...  \n",
       "95  iphone 11 is a very good phone to buy only if ...  \n",
       "96  It’s a must buy who is looking for an upgrade ...  \n",
       "97  Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "98  This is my first iOS phone. I am very happy wi...  \n",
       "99  *Review after 10 months of usage*\\nDoesn't see...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Creating empty list\n",
    "urls=[]\n",
    "short_review=[]\n",
    "complete_review=[]\n",
    "stars=[]\n",
    "\n",
    "time.sleep(4)\n",
    "#Taking 10 pages into consideration using for loop\n",
    "for i in range(10):\n",
    "    url=driver.find_element_by_xpath(\"//a[@class='ge-49M']\").get_attribute('href')\n",
    "    driver.get(url)\n",
    "    #for scrapping the number of stars\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        stars.append(j.text)\n",
    "    #for scrapping the short review\n",
    "    for k in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        short_review.append(k.text)\n",
    "    #for scrapping the complete review\n",
    "    for l in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\"):\n",
    "        complete_review.append(l.text)\n",
    "        \n",
    "        \n",
    "        \n",
    "#Combining all the lists into a single dataframe\n",
    "df=pd.DataFrame({'Number of Stars': stars,\n",
    "                'Short Review': short_review,\n",
    "               'Full Review': complete_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q8:Scrape data for first 100 sneakers you find when you visit flipkart.comand search for “sneakers” in the search field.You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "Also note that all the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skymate</td>\n",
       "      <td>Sneakers For Men  (Beige)</td>\n",
       "      <td>₹224</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STRANGER BROTHERS</td>\n",
       "      <td>Men Running Flat PU Synthetic Sneakers Male Bl...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Sneakers For Men  (Navy, Orange)</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Sneakers For Men  (White)</td>\n",
       "      <td>₹298</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOTSTYLE</td>\n",
       "      <td>Casual Sneaker Sneakers For Men  (Orange)</td>\n",
       "      <td>₹283</td>\n",
       "      <td>43% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>believe</td>\n",
       "      <td>Cape IDP Sneakers For Men  (Green)</td>\n",
       "      <td>₹446</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3SIX5</td>\n",
       "      <td>casual sneakers and loafers shoes For Mens Com...</td>\n",
       "      <td>₹398</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Skymate</td>\n",
       "      <td>Modern Trendy Shoes Combo pack of 2 Perfect &amp; ...</td>\n",
       "      <td>₹224</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Billion</td>\n",
       "      <td>Rockstyle Trending Multicolor Ultralight canva...</td>\n",
       "      <td>₹223</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>bluemaker</td>\n",
       "      <td>Skate Board White Shoes Men Running Flat PU Sn...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                        Description  \\\n",
       "0             Skymate                          Sneakers For Men  (Beige)   \n",
       "1   STRANGER BROTHERS  Men Running Flat PU Synthetic Sneakers Male Bl...   \n",
       "2        Robbie jones                   Sneakers For Men  (Navy, Orange)   \n",
       "3                aadi                          Sneakers For Men  (White)   \n",
       "4            HOTSTYLE          Casual Sneaker Sneakers For Men  (Orange)   \n",
       "..                ...                                                ...   \n",
       "95            believe                 Cape IDP Sneakers For Men  (Green)   \n",
       "96              3SIX5  casual sneakers and loafers shoes For Mens Com...   \n",
       "97            Skymate  Modern Trendy Shoes Combo pack of 2 Perfect & ...   \n",
       "98            Billion  Rockstyle Trending Multicolor Ultralight canva...   \n",
       "99          bluemaker  Skate Board White Shoes Men Running Flat PU Sn...   \n",
       "\n",
       "   Price Discount  \n",
       "0   ₹224  55% off  \n",
       "1   ₹474  52% off  \n",
       "2   ₹399  60% off  \n",
       "3   ₹298  70% off  \n",
       "4   ₹283  43% off  \n",
       "..   ...      ...  \n",
       "95  ₹446  60% off  \n",
       "96  ₹398  55% off  \n",
       "97  ₹224  81% off  \n",
       "98  ₹223  52% off  \n",
       "99  ₹474  55% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "#close log_in window\n",
    "log_in_pop_up = driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "log_in_pop_up.click()\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the search bar\n",
    "search_bar=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('sneakers')\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the button and clicking it to search for sneakers\n",
    "button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "button.click()\n",
    "\n",
    "\n",
    "#creating the empty list\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "#scrapping the required details\n",
    "start=0\n",
    "end=4\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    brands=driver.find_elements_by_class_name('_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")# scraping the price from the xpath\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    disc=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")# scraping the discount from the xpath\n",
    "    for i in disc:\n",
    "        discount.append(i.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "        \n",
    "        \n",
    "time.sleep(2)        \n",
    "# Since in some records not getting description so try from inside of urls\n",
    "urls = []\n",
    "\n",
    "for page in range(0,4):#for loop for scrapping 4 page\n",
    "    \n",
    "    product_url = driver.find_elements_by_xpath(\"//a[@class='_2UzuFa']\")\n",
    "    for i in product_url:\n",
    "        urls.append(i.get_attribute('href'))\n",
    "    \n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "time.sleep(2)        \n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    desc=driver.find_elements_by_xpath('//span[@class=\"B_NuCI\"]')#scraping description from the xpath\n",
    "    for i in desc:\n",
    "        description.append(i.text)#appending the description in list\n",
    "time.sleep(2)        \n",
    "time.sleep(3)        \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Brand':brand[:100],\n",
    "                'Description':description[:100],\n",
    "                'Price':price[:100],\n",
    "                'Discount':discount[:100]})\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9.\"https://www.myntra.com/shoes\". \n",
    "Set price filter \"Rs 6649 to Rs 13099\" and color filter to \"Black\" and then scrap 100 shoes data. The data should include \"Brand\" of shoes, shoe short-description and price. Please not: Everything should done through code even the filtering for sneakers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.myntra.com/shoes%22\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "#clicking on price filter\n",
    "price_button = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "price_button.click()\n",
    "\n",
    "#clicking on black color filter\n",
    "black_color_button = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n",
    "black_color_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Short-description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women Charged Breathe OIL SLK</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Liberate Nitro Running</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>NIKE DBREAK Sneakers</td>\n",
       "      <td>Rs. 6795Rs. 7995(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reebok</td>\n",
       "      <td>Forever Floatride Energy 2</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Unisex SC 3ZER0 IV Basketball</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Men Solid Casual Sneakers</td>\n",
       "      <td>Rs. 8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Ignite Sock Plus Sneakers</td>\n",
       "      <td>Rs. 8796Rs. 10995(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Formal Brogues</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Mid-Top Sneakers</td>\n",
       "      <td>Rs. 11895Rs. 13995(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Women Leather Sneakers</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand              Short-description                        Price\n",
       "0   UNDER ARMOUR  Women Charged Breathe OIL SLK                     Rs. 8999\n",
       "1           Puma     Men Liberate Nitro Running                     Rs. 9999\n",
       "2           Nike           NIKE DBREAK Sneakers    Rs. 6795Rs. 7995(15% OFF)\n",
       "3         Reebok     Forever Floatride Energy 2                     Rs. 9999\n",
       "4   UNDER ARMOUR  Unisex SC 3ZER0 IV Basketball                     Rs. 8999\n",
       "..           ...                            ...                          ...\n",
       "95       Saint G      Men Solid Casual Sneakers                     Rs. 8500\n",
       "96          Nike  Men Ignite Sock Plus Sneakers   Rs. 8796Rs. 10995(20% OFF)\n",
       "97          ALDO             Men Formal Brogues                     Rs. 9999\n",
       "98          Nike         Women Mid-Top Sneakers  Rs. 11895Rs. 13995(15% OFF)\n",
       "99          ALDO         Women Leather Sneakers                     Rs. 9999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty lists\n",
    "shoe_names=[]\n",
    "s_desc=[]\n",
    "short_desc=[]\n",
    "price=[]\n",
    "page_urls = []\n",
    "\n",
    "time.sleep(4)\n",
    "# scrape next pages urls\n",
    "nxt_page = driver.find_elements_by_xpath(\"//li[@class='pagination-number']/a\")\n",
    "for i in nxt_page:\n",
    "    page_urls.append(i.get_attribute('href'))\n",
    "    \n",
    "\n",
    "for url in page_urls[:3]:\n",
    "    driver.get(url)\n",
    "    Names=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")  #for scrapping shoe brand names\n",
    "    for i in Names:\n",
    "        shoe_names.append(i.text)\n",
    "    \n",
    "    desc=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4\") #for scrapping shoe short-description\n",
    "    for i in desc:\n",
    "        s_desc.append(i.text)\n",
    "    #As, the s_desc list contain blank description in every alternate index, so removing the blank or null description\n",
    "    for j in range(0,len(s_desc),2):\n",
    "        short_desc.append(s_desc[j])\n",
    "    \n",
    "    rs=driver.find_elements_by_xpath(\"//div[@class='product-price']\")  #for scrapping shoe prices\n",
    "    for i in rs:\n",
    "        price.append(i.text)    \n",
    "        \n",
    "df=pd.DataFrame({'Brand': shoe_names[:100],'Short-description': short_desc[:100],'Price': price[:100]})\n",
    "df        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q10:  Go to webpage https://www.amazon.in/Enter “Laptop” in the search field and then click the search icon.Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”\n",
    "After setting the filters scrape first 10 laptops data.You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell Inspiron 15 5501 10thGen Corei7-10657G7 8...</td>\n",
       "      <td>91,990</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...</td>\n",
       "      <td>1,02,000</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...</td>\n",
       "      <td>77,980</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>54,999</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo Legion 5 10th Gen Intel Core i7 15.6 in...</td>\n",
       "      <td>86,290</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dell G3 3500 Gaming Laptop 15.6\" (39.62cms) FH...</td>\n",
       "      <td>61,799</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Renewed) Dell Intel 6th Gen Core i7-6820HQ 15...</td>\n",
       "      <td>76,990</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Pavilion x360 Touchscreen 2-in-1 FHD 14\" (3...</td>\n",
       "      <td>36,990</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>77,937</td>\n",
       "      <td>3.2 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...</td>\n",
       "      <td>78,699</td>\n",
       "      <td>3.5 out of 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Price       Ratings\n",
       "0  Dell Inspiron 15 5501 10thGen Corei7-10657G7 8...    91,990  4.3 out of 5\n",
       "1  ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...  1,02,000  4.4 out of 5\n",
       "2  ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...    77,980  4.4 out of 5\n",
       "3  Mi Notebook Horizon Edition 14 Intel Core i5-1...    54,999  4.4 out of 5\n",
       "4  Lenovo Legion 5 10th Gen Intel Core i7 15.6 in...    86,290  4.4 out of 5\n",
       "5  Dell G3 3500 Gaming Laptop 15.6\" (39.62cms) FH...    61,799  4.1 out of 5\n",
       "6  (Renewed) Dell Intel 6th Gen Core i7-6820HQ 15...    76,990     NO rating\n",
       "7  HP Pavilion x360 Touchscreen 2-in-1 FHD 14\" (3...    36,990  4.1 out of 5\n",
       "8  Life Digital Laptop 15.6-inch (39.62 cms) (Int...    77,937  3.2 out of 5\n",
       "9  HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...    78,699  3.5 out of 5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.amazon.in/ref=nav_logo\"\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "#creating the empty list\n",
    "Title=[]\n",
    "Ratings=[]\n",
    "price=[]\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the search bar\n",
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")    # Locating searc_bar by id\n",
    "search_bar.clear()                                               # clearing search_bar\n",
    "search_bar.send_keys(\"laptops\")                                   # sending user input to search bar\n",
    "search_button = driver.find_element_by_xpath('//span[@id=\"nav-search-submit-text\"]')       # Locating search_button by xpath\n",
    "search_button.click()    \n",
    "\n",
    "time.sleep(2)\n",
    "#locating the core i7 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break\n",
    "        \n",
    "        \n",
    "#Scrapping Titles\n",
    "titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in titles[:10]:\n",
    "    Title.append(i.text)\n",
    "    \n",
    "    \n",
    "#scrapping Price\n",
    "prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in prices[:10]:\n",
    "    price.append(i.text)\n",
    "\n",
    "#locating Ratings\n",
    "urls=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")#collecting urls of all the laptop\n",
    "UR=[]\n",
    "for i in urls[:10]:\n",
    "    UR.append(i.get_attribute('href'))#getting the url of first 10 laptops\n",
    "for url in UR:#loop for every laptop in the list\n",
    "    driver.get(url)\n",
    "    try:                  #exception handling for nosuchelementexception                                                    #click the rating link found\n",
    "        rating=driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']//span\")#locating the rating\n",
    "        Ratings.append(rating.text)#appending the ratings in Ratings list\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Ratings.append(\"NO rating\")#appending the No rating if no rating is there\n",
    "        \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Title':Title,\n",
    "                'Price':price,\n",
    "                'Ratings':Ratings})\n",
    "#printing dataframe\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
