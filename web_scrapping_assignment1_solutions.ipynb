{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 1 - display all the header tags from \n",
    "‘en.wikipedia.org/wiki/Main_Page’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h1 Main Page',\n",
       " \"h2 From today's featured article\",\n",
       " 'h2 Did you know\\xa0...',\n",
       " 'h2 In the news',\n",
       " 'h2 On this day',\n",
       " \"h2 From today's featured list\",\n",
       " \"h2 Today's featured picture\",\n",
       " 'h2 Other areas of Wikipedia',\n",
       " \"h2 Wikipedia's sister projects\",\n",
       " 'h2 Wikipedia languages',\n",
       " 'h2 Navigation menu',\n",
       " 'h3 Personal tools',\n",
       " 'h3 Namespaces',\n",
       " 'h3 Variants',\n",
       " 'h3 Views',\n",
       " 'h3 More',\n",
       " 'h3 Search',\n",
       " 'h3 Navigation',\n",
       " 'h3 Contribute',\n",
       " 'h3 Tools',\n",
       " 'h3 Print/export',\n",
       " 'h3 In other projects',\n",
       " 'h3 Languages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page = requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "\n",
    "# page content\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "header_tags = [] # empty list\n",
    "for header in soup.find_all([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\",\"h6\"]):\n",
    "    header_tags.append(header.name+\" \"+header.text.strip())\n",
    "    \n",
    "# print all header_tags\n",
    "header_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 2 - IMDB’s Top rated 100 movies’ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movies_name</th>\n",
       "      <th>year_of_release</th>\n",
       "      <th>IMDB_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>(1974)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>(1957)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>(1959)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>(1971)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Snatch</td>\n",
       "      <td>(2000)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Amélie</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Kid</td>\n",
       "      <td>(1921)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 movies_name year_of_release  IMDB_rating\n",
       "0   The Shawshank Redemption          (1994)          9.3\n",
       "1              The Godfather          (1972)          9.2\n",
       "2     The Godfather: Part II          (1974)          9.0\n",
       "3            The Dark Knight          (2008)          9.0\n",
       "4               12 Angry Men          (1957)          9.0\n",
       "..                       ...             ...          ...\n",
       "95        North by Northwest          (1959)          8.3\n",
       "96        A Clockwork Orange          (1971)          8.3\n",
       "97                    Snatch          (2000)          8.3\n",
       "98                    Amélie          (2001)          8.3\n",
       "99                   The Kid          (1921)          8.3\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.imdb.com/list/ls091520106/\"\n",
    "page2 = requests.get(url)\n",
    "\n",
    "#see page content\n",
    "soup2 = BeautifulSoup(page2.content)\n",
    "\n",
    "# top Movies name\n",
    "name = soup2.find_all(\"h3\", class_=\"lister-item-header\")\n",
    "# get text from movie name web elements\n",
    "movies_name = [] #empty list\n",
    "for i in name:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        movies_name.append(j.text)\n",
    "\n",
    "\n",
    "# Year of release\n",
    "year = soup2.find_all(\"span\",class_=\"lister-item-year text-muted unbold\")\n",
    "year_of_release = [] #empty list\n",
    "for k in year:\n",
    "    year_of_release.append(k.text)\n",
    "\n",
    "      \n",
    "# IMDB Rating\n",
    "rating = soup2.find_all(\"div\",class_=\"ipl-rating-star small\")\n",
    "\n",
    "# scrape text from rating web element\n",
    "IMDB_rating = [] #empty list\n",
    "for i in rating:\n",
    "      IMDB_rating.append(float(i.text))\n",
    "# Make data frame of top 100 movies on IMDB\n",
    "IMDB_top_100=pd.DataFrame({})\n",
    "IMDB_top_100['movies_name']=movies_name\n",
    "IMDB_top_100['year_of_release']=year_of_release\n",
    "IMDB_top_100['IMDB_rating']=IMDB_rating  \n",
    "IMDB_top_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question-3 IMDB’s Top rated 100 Indian movies’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movies_name</th>\n",
       "      <th>year_of_release</th>\n",
       "      <th>IMDB_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rang De Basanti</td>\n",
       "      <td>(2006)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>(2009)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taare Zameen Par</td>\n",
       "      <td>(2007)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dil Chahta Hai</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Swades: We, the People</td>\n",
       "      <td>(2004)</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Wake Up Sid</td>\n",
       "      <td>(2009)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Rangeela</td>\n",
       "      <td>(1995)</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Shatranj Ke Khilari</td>\n",
       "      <td>(1977)</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Pyaar Ka Punchnama</td>\n",
       "      <td>(2011)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ek Hasina Thi</td>\n",
       "      <td>(2004)</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               movies_name year_of_release  IMDB_rating\n",
       "0          Rang De Basanti          (2006)          8.1\n",
       "1                 3 Idiots          (2009)          8.4\n",
       "2         Taare Zameen Par          (2007)          8.4\n",
       "3           Dil Chahta Hai          (2001)          8.1\n",
       "4   Swades: We, the People          (2004)          8.2\n",
       "..                     ...             ...          ...\n",
       "95             Wake Up Sid          (2009)          7.6\n",
       "96                Rangeela          (1995)          7.5\n",
       "97     Shatranj Ke Khilari          (1977)          7.7\n",
       "98      Pyaar Ka Punchnama          (2011)          7.6\n",
       "99           Ek Hasina Thi          (2004)          7.5\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.imdb.com/list/ls009997493/\"\n",
    "page3 = requests.get(url)\n",
    "\n",
    "# check the page content\n",
    "soup3 = BeautifulSoup(page3.content)\n",
    "\n",
    "# top Movies name\n",
    "name = soup3.find_all(\"h3\", class_=\"lister-item-header\")\n",
    "# get text from movie name web elements\n",
    "movies_name = [] #empty list\n",
    "for i in name:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        movies_name.append(j.text)\n",
    "\n",
    "\n",
    "# Year of release\n",
    "year = soup3.find_all(\"span\",class_=\"lister-item-year text-muted unbold\")\n",
    "year_of_release = [] #empty list\n",
    "for k in year:\n",
    "    year_of_release.append(k.text)\n",
    "\n",
    "\n",
    "# IMDB Rating\n",
    "rating = soup3.find_all(\"div\",class_=\"ipl-rating-star small\")\n",
    "\n",
    "# scrape text from rating web element\n",
    "IMDB_rating = [] #empty list\n",
    "for i in rating:\n",
    "      IMDB_rating.append(float(i.text))\n",
    "# Make data frame of top 100 India imdb movies\n",
    "indian_top_100=pd.DataFrame({})\n",
    "indian_top_100['movies_name']=movies_name\n",
    "indian_top_100['year_of_release']=year_of_release\n",
    "indian_top_100['IMDB_rating']=IMDB_rating\n",
    "indian_top_100    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 4 - scrap book name, author name, genre and book review of \n",
    "any 5 books from ‘www.bookpage.com’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facing the Mountain</td>\n",
       "      <td>Daniel James Brown</td>\n",
       "      <td>Nonfiction / History / American History</td>\n",
       "      <td>Imagine that you and your family have been tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lucky Girl</td>\n",
       "      <td>Jamie Pacton</td>\n",
       "      <td>YA Fiction / YA</td>\n",
       "      <td>Seventeen-year-old Jane Belleweather has just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On Juneteenth</td>\n",
       "      <td>Annette Gordon-Reed</td>\n",
       "      <td>Nonfiction / History / American History</td>\n",
       "      <td>Annette Gordon-Reed opens On Juneteenth by ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pawcasso</td>\n",
       "      <td>Remy Lai</td>\n",
       "      <td>Children's / Middle Grade</td>\n",
       "      <td>Pawcasso is a joyful graphic novel from acclai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Most Beautiful Girl in Cuba</td>\n",
       "      <td>Chanel Cleeton</td>\n",
       "      <td>Fiction / Historical Fiction</td>\n",
       "      <td>Through her popular historical novels, bestsel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Book Name               Author  \\\n",
       "0              Facing the Mountain   Daniel James Brown   \n",
       "1                       Lucky Girl         Jamie Pacton   \n",
       "2                    On Juneteenth  Annette Gordon-Reed   \n",
       "3                         Pawcasso             Remy Lai   \n",
       "4  The Most Beautiful Girl in Cuba       Chanel Cleeton   \n",
       "\n",
       "                                     Genre  \\\n",
       "0  Nonfiction / History / American History   \n",
       "1                          YA Fiction / YA   \n",
       "2  Nonfiction / History / American History   \n",
       "3                Children's / Middle Grade   \n",
       "4             Fiction / Historical Fiction   \n",
       "\n",
       "                                              Review  \n",
       "0  Imagine that you and your family have been tak...  \n",
       "1  Seventeen-year-old Jane Belleweather has just ...  \n",
       "2  Annette Gordon-Reed opens On Juneteenth by ref...  \n",
       "3  Pawcasso is a joyful graphic novel from acclai...  \n",
       "4  Through her popular historical novels, bestsel...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "\n",
    "page4 = requests.get('https://bookpage.com/reviews/')\n",
    "soup4 = BeautifulSoup(page4.content, 'html.parser')\n",
    "url_tags = soup4.find_all(\"h4\",class_=\"italic\") # Extract books URL\n",
    "urls = []\n",
    "for i in url_tags:\n",
    "    for j in i.find_all(\"a\", href=True):\n",
    "        if j.text:\n",
    "            urls.append(j['href'])\n",
    "book_name = [] #empty list\n",
    "author_name = [] #empty list\n",
    "book_genre = [] #empty list\n",
    "books_review = [] #empty list\n",
    "\n",
    "for url in urls:\n",
    "        book = requests.get('https://www.bookpage.com'+url)\n",
    "        soup = BeautifulSoup(book.content, 'html.parser')\n",
    "        book_name.append(soup.find('h1').text.replace('\\n','').replace('★',''))  # scrape books name\n",
    "        author_name.append(soup.find('h4').text.replace('\\n',''))  # scrape books author name\n",
    "        book_genre.append(soup.find('p', class_=\"genre-links\").text.replace('\\n',''))   # scrape books genre\n",
    "        books_review.append(soup.find('div', class_= \"article-body\").text.replace('\\n',''))  # scrape books review\n",
    "        \n",
    "\n",
    "# Make data frame \n",
    "books=pd.DataFrame({})\n",
    "books[\"Book Name\"]=book_name[:5]\n",
    "books[\"Author\"]=author_name[:5]\n",
    "books[\"Genre\"]=book_genre[:5]\n",
    "books[\"Review\"]=books_review[:5]\n",
    "books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 5 -  scrape cricket rankings from ‘www.icc-cricket.com’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* i) Top 10 ODI teams in men’s cricket along with the records for matches, points and \n",
    "rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>25</td>\n",
       "      <td>2,945</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>29</td>\n",
       "      <td>3,344</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>27</td>\n",
       "      <td>3,100</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>20</td>\n",
       "      <td>2,137</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>24</td>\n",
       "      <td>2,323</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>24</td>\n",
       "      <td>2,157</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>27</td>\n",
       "      <td>2,222</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>21</td>\n",
       "      <td>1,652</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team_name Matches Points  \\\n",
       "0   New Zealand      17  2,054   \n",
       "1     Australia      25  2,945   \n",
       "2         India      29  3,344   \n",
       "3       England      27  3,100   \n",
       "4  South Africa      20  2,137   \n",
       "5      Pakistan      24  2,323   \n",
       "6    Bangladesh      24  2,157   \n",
       "7   West Indies      27  2,222   \n",
       "8     Sri Lanka      21  1,652   \n",
       "9   Afghanistan      17  1,054   \n",
       "\n",
       "                                             Ratings  \n",
       "0                              121               ...  \n",
       "1                                                118  \n",
       "2                                                115  \n",
       "3                                                115  \n",
       "4                                                107  \n",
       "5                                                 97  \n",
       "6                                                 90  \n",
       "7                                                 82  \n",
       "8                                                 79  \n",
       "9                                                 62  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "page5 = requests.get(url)\n",
    "# see content in page5\n",
    "soup5 = BeautifulSoup(page5.content)\n",
    "#scrape team names\n",
    "team = soup5.find_all(\"span\",class_='u-hide-phablet')\n",
    "team_name = []\n",
    "for i in team:\n",
    "    team_name.append(i.text)\n",
    "matches = [] #empty list\n",
    "points = [] #empty list\n",
    "ratings = [] #empty list\n",
    "new_list = [] #empty list\n",
    "\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--matches'): # first place team number of matches\n",
    "    matches.append(i.text)\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--points'):# first place team points\n",
    "    points.append(i.text)\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--rating u-text-right'):# first place team ratings\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell u-center-text'):# other teams number of matches and points\n",
    "    new_list.append(i.text)\n",
    "for i in range(0,len(new_list)-1,2):\n",
    "    matches.append(new_list[i]) # other teams matches\n",
    "    points.append(new_list[i+1]) # other teams points\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell u-text-right rating'):# other teams number of matches and ratings\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "# Make data frame of top 10 ICC teams\n",
    "icc=pd.DataFrame({})\n",
    "icc['Team_name']=team_name[:10]\n",
    "icc['Matches']=matches[:10]\n",
    "icc['Points']=points[:10]\n",
    "icc['Ratings']=ratings[:10]\n",
    "icc    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ii) Top 10 ODI Batsmen in men along with the records of their team and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Francois du Plessis</td>\n",
       "      <td>SA</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player                     Team Rating\n",
       "0           Babar Azam  PAK                        865\n",
       "1          Virat Kohli                      IND    857\n",
       "2         Rohit Sharma                      IND    825\n",
       "3          Ross Taylor                       NZ    801\n",
       "4          Aaron Finch                      AUS    791\n",
       "5       Jonny Bairstow                      ENG    785\n",
       "6         Fakhar Zaman                      PAK    778\n",
       "7  Francois du Plessis                       SA    778\n",
       "8         David Warner                      AUS    773\n",
       "9            Shai Hope                       WI    773"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "page6 = requests.get(url)\n",
    "# see content in page6\n",
    "soup6 = BeautifulSoup(page6.content)\n",
    "players = [] #empty list\n",
    "team_name = [] #empty list\n",
    "rating = [] #empty list\n",
    "\n",
    "for i in soup6.find_all(\"div\",class_='rankings-block__banner--name-large'): # first place player name\n",
    "    players.append(i.text)\n",
    "for i in soup6.find_all(\"div\",class_='rankings-block__banner--nationality'): # first place player team name\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup6.find_all(\"div\",class_='rankings-block__banner--rating'): # first place player rating\n",
    "    rating.append(i.text)\n",
    "for i in soup6.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup6.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup6.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "# Make data frame of top 10 ICC Batsmen\n",
    "Batsmen=pd.DataFrame({})\n",
    "Batsmen['Player']=players[:10]\n",
    "Batsmen['Team']=team_name[:10]\n",
    "Batsmen['Rating']=rating[:10]\n",
    "Batsmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* iii) Top 10 ODI bowlers along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>AUS</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mohammad Amir</td>\n",
       "      <td>PAK</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player                    Team Rating\n",
       "0       Trent Boult  NZ                        737\n",
       "1  Mujeeb Ur Rahman                     AFG    708\n",
       "2        Matt Henry                      NZ    691\n",
       "3    Jasprit Bumrah                     IND    690\n",
       "4      Mehedi Hasan                     BAN    668\n",
       "5     Kagiso Rabada                      SA    666\n",
       "6      Chris Woakes                     ENG    665\n",
       "7    Josh Hazlewood                     AUS    660\n",
       "8       Pat Cummins                     AUS    646\n",
       "9     Mohammad Amir                     PAK    638"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "page7 = requests.get(url)\n",
    "\n",
    "# see content in page7\n",
    "soup7 = BeautifulSoup(page7.content)\n",
    "\n",
    "players = [] #empty list\n",
    "team_name = [] #empty list  \n",
    "rating = [] #empty list \n",
    "\n",
    "for i in soup7.find_all(\"div\",class_='rankings-block__banner--name-large'): # first place player name\n",
    "    players.append(i.text)\n",
    "for i in soup7.find_all(\"div\",class_='rankings-block__banner--nationality'): # first place player team name\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup7.find_all(\"div\",class_='rankings-block__banner--rating'): # first place player rating\n",
    "    rating.append(i.text)\n",
    "for i in soup7.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup7.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup7.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "# Make data frame of top 10 ICC bowlers\n",
    "bowlers=pd.DataFrame({})\n",
    "bowlers['Player']=players[:10]\n",
    "bowlers['Team']=team_name[:10]\n",
    "bowlers['Rating']=rating[:10]\n",
    "bowlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 6 - Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* i) Top 10 ODI teams in women’s cricket along with the records for matches, points \n",
    "and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>2,955</td>\n",
       "      <td>164               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,828</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>17</td>\n",
       "      <td>1,993</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>20</td>\n",
       "      <td>2,226</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>21</td>\n",
       "      <td>1,947</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>12</td>\n",
       "      <td>1,025</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>15</td>\n",
       "      <td>1,101</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team_name Matches Points  \\\n",
       "0     Australia      18  2,955   \n",
       "1  South Africa      24  2,828   \n",
       "2       England      17  1,993   \n",
       "3         India      20  2,226   \n",
       "4   New Zealand      21  1,947   \n",
       "5   West Indies      12  1,025   \n",
       "6      Pakistan      15  1,101   \n",
       "7    Bangladesh       5    306   \n",
       "8     Sri Lanka      11    519   \n",
       "9       Ireland       2     25   \n",
       "\n",
       "                                             Ratings  \n",
       "0                              164               ...  \n",
       "1                                                118  \n",
       "2                                                117  \n",
       "3                                                111  \n",
       "4                                                 93  \n",
       "5                                                 85  \n",
       "6                                                 73  \n",
       "7                                                 61  \n",
       "8                                                 47  \n",
       "9                                                 13  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "page8 = requests.get(url)\n",
    "#see content in page8\n",
    "soup8 = BeautifulSoup(page8.content)\n",
    "#scrape team names\n",
    "womens_team = soup8.find_all(\"span\",class_='u-hide-phablet')\n",
    "womens_team_name = []\n",
    "for i in womens_team:\n",
    "    womens_team_name.append(i.text)\n",
    "womens_matches = [] #empty list\n",
    "womens_points = [] #empty list\n",
    "womens_ratings = [] #empty list\n",
    "womens_new_list = [] #empty list\n",
    "for i in soup8.find_all(\"td\",class_='rankings-block__banner--matches'): # first place team number of matches\n",
    "    womens_matches.append(i.text)\n",
    "for i in soup8.find_all(\"td\",class_='rankings-block__banner--points'):# first place team points\n",
    "    womens_points.append(i.text)\n",
    "for i in soup8.find_all(\"td\",class_='rankings-block__banner--rating u-text-right'):# first place team ratings\n",
    "    womens_ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup8.find_all(\"td\",class_='table-body__cell u-center-text'):# other teams number of matches and points\n",
    "    womens_new_list.append(i.text)\n",
    "for i in range(0,len(womens_new_list)-1,2):\n",
    "    womens_matches.append(womens_new_list[i]) # other teams matches\n",
    "    womens_points.append(womens_new_list[i+1]) # other teams points\n",
    "for i in soup8.find_all(\"td\",class_='table-body__cell u-text-right rating'):# other teams number of matches and ratings\n",
    "    womens_ratings.append(i.text)\n",
    "# Make data frame of top 10 ICC teams\n",
    "womens_icc=pd.DataFrame({})\n",
    "womens_icc['Team_name']=womens_team_name[:10]\n",
    "womens_icc['Matches']=womens_matches[:10]\n",
    "womens_icc['Points']=womens_points[:10]\n",
    "womens_icc['Ratings']=womens_ratings[:10]\n",
    "womens_icc    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ii) Top 10 women’s ODI players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player                     Team Rating\n",
       "0     Tammy Beaumont  ENG                        765\n",
       "1        Lizelle Lee                       SA    758\n",
       "2       Alyssa Healy                      AUS    756\n",
       "3    Stafanie Taylor                       WI    746\n",
       "4        Meg Lanning                      AUS    723\n",
       "5  Amy Satterthwaite                       NZ    715\n",
       "6    Smriti Mandhana                      IND    710\n",
       "7        Mithali Raj                      IND    709\n",
       "8     Natalie Sciver                      ENG    685\n",
       "9    Laura Wolvaardt                       SA    683"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "page9 = requests.get(url)\n",
    "# see content in page9\n",
    "soup9 = BeautifulSoup(page9.content)\n",
    "players = [] #empty list\n",
    "team_name = [] #empty list\n",
    "rating = [] #empty list\n",
    "\n",
    "for i in soup9.find_all(\"div\",class_='rankings-block__banner--name-large'): # first place player name\n",
    "    players.append(i.text)\n",
    "for i in soup9.find_all(\"div\",class_='rankings-block__banner--nationality'): # first place player team name\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup9.find_all(\"div\",class_='rankings-block__banner--rating'): # first place player rating\n",
    "    rating.append(i.text)\n",
    "for i in soup9.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup9.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup9.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "# Make data frame of top 10 Women's ODI Batting Rankings\n",
    "top_players=pd.DataFrame({})\n",
    "top_players['Player']=players[:10]\n",
    "top_players['Team']=team_name[:10]\n",
    "top_players['Rating']=rating[:10]\n",
    "top_players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* iii)Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player                    Team Rating\n",
       "0    Marizanne Kapp  SA                        418\n",
       "1      Ellyse Perry                     AUS    418\n",
       "2   Stafanie Taylor                      WI    410\n",
       "3    Natalie Sciver                     ENG    349\n",
       "4     Deepti Sharma                     IND    343\n",
       "5     Jess Jonassen                     AUS    307\n",
       "6  Ashleigh Gardner                     AUS    252\n",
       "7  Dane van Niekerk                      SA    243\n",
       "8     Sophie Devine                      NZ    242\n",
       "9       Amelia Kerr                      NZ    236"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "page10 = requests.get(url)\n",
    "\n",
    "# see content in page10\n",
    "soup10 = BeautifulSoup(page10.content)\n",
    "\n",
    "players = [] #empty list\n",
    "team_name = [] #empty list  \n",
    "rating = [] #empty list \n",
    "\n",
    "for i in soup10.find_all(\"div\",class_='rankings-block__banner--name-large'): # first place player name\n",
    "    players.append(i.text)\n",
    "for i in soup10.find_all(\"div\",class_='rankings-block__banner--nationality'): # first place player team name\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup10.find_all(\"div\",class_='rankings-block__banner--rating'): # first place player rating\n",
    "    rating.append(i.text)\n",
    "for i in soup10.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup10.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup10.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "# Make data frame of top 10 ICC Women's ODI All-Rounder Rankings\n",
    "all_rounder=pd.DataFrame({})\n",
    "all_rounder['Player']=players[:10]\n",
    "all_rounder['Team']=team_name[:10]\n",
    "all_rounder['Rating']=rating[:10]\n",
    "all_rounder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 7 - scrape details of all the mobile phones under Rs. 20,000 \n",
    "listed on Amazon.in. The scraped data should include Product Name, Price, Image URL \n",
    "and Average Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>img_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Redmi 9A (Nature Green, 2GB Ram, 32GB Storage)...</td>\n",
       "      <td>12,499</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>https://images-eu.ssl-images-amazon.com/images...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oppo A31 (Fantasy White, 6GB RAM, 128GB Storag...</td>\n",
       "      <td>14,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61ovWQUYp7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vivo Y91i (Fusion Black, 2GB RAM, 32GB Storage...</td>\n",
       "      <td>11,999</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71dujTTJDZ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vivo Y91i (Ocean Blue, 3GB RAM, 32GB Storage) ...</td>\n",
       "      <td>6,799</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71-Su4Wr0H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage)| 500...</td>\n",
       "      <td>10,990</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81fwKtv0VH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samsung Galaxy M31s (Mirage Blue, 6GB RAM, 128...</td>\n",
       "      <td>7,490</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71sxlhYhKW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Samsung Galaxy M21 (Midnight Blue, 4GB RAM, 64...</td>\n",
       "      <td>7,990</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61IhTtJUXJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Oppo A52 (Twilight Black, 6GB RAM, 128GB Stora...</td>\n",
       "      <td>8,499</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51ZoulFBPG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vivo Y91i (Ocean Blue, 2GB RAM, 32GB Storage) ...</td>\n",
       "      <td>16,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51-T19jXch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Redmi 9 Prime (Sunrise Flare, 4GB RAM, 64GB St...</td>\n",
       "      <td>12,499</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71A9Vo1Bat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Oppo A31 (Mystery Black, 6GB RAM, 128GB Storag...</td>\n",
       "      <td>13,990</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61d-phh4Gf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Samsung Galaxy M31 (Space Black, 6GB RAM, 128G...</td>\n",
       "      <td>7,490</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71dujTTJDZ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Panasonic Eluga i7 (2GB RAM, 16GB Storage, Fin...</td>\n",
       "      <td>9,999</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71FPmXaDfb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Samsung Galaxy M31 (Ocean Blue, 6GB RAM, 128GB...</td>\n",
       "      <td>10,990</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51FnmxwFHD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Samsung Galaxy M02s (Blue,4GB RAM, 64GB Storag...</td>\n",
       "      <td>14,999</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71U2SiHgbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Samsung Galaxy M12 (Blue,6GB RAM, 128GB Storag...</td>\n",
       "      <td>5,000</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71KCwNV6Mu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         product_name   price  \\\n",
       "0   Redmi 9A (Nature Green, 2GB Ram, 32GB Storage)...  12,499   \n",
       "1   Oppo A31 (Fantasy White, 6GB RAM, 128GB Storag...  14,999   \n",
       "2   Vivo Y91i (Fusion Black, 2GB RAM, 32GB Storage...  11,999   \n",
       "3   Vivo Y91i (Ocean Blue, 3GB RAM, 32GB Storage) ...   6,799   \n",
       "4   Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage)| 500...  10,990   \n",
       "5   Samsung Galaxy M31s (Mirage Blue, 6GB RAM, 128...   7,490   \n",
       "6   Samsung Galaxy M21 (Midnight Blue, 4GB RAM, 64...   7,990   \n",
       "7   Oppo A52 (Twilight Black, 6GB RAM, 128GB Stora...   8,499   \n",
       "8   Vivo Y91i (Ocean Blue, 2GB RAM, 32GB Storage) ...  16,999   \n",
       "9   Redmi 9 Prime (Sunrise Flare, 4GB RAM, 64GB St...  12,499   \n",
       "10  Oppo A31 (Mystery Black, 6GB RAM, 128GB Storag...  13,990   \n",
       "11  Samsung Galaxy M31 (Space Black, 6GB RAM, 128G...   7,490   \n",
       "12  Panasonic Eluga i7 (2GB RAM, 16GB Storage, Fin...   9,999   \n",
       "13  Samsung Galaxy M31 (Ocean Blue, 6GB RAM, 128GB...  10,990   \n",
       "14  Samsung Galaxy M02s (Blue,4GB RAM, 64GB Storag...  14,999   \n",
       "15  Samsung Galaxy M12 (Blue,6GB RAM, 128GB Storag...   5,000   \n",
       "\n",
       "                Rating                                            img_url  \n",
       "0   4.3 out of 5 stars  https://images-eu.ssl-images-amazon.com/images...  \n",
       "1   4.2 out of 5 stars  https://m.media-amazon.com/images/I/61ovWQUYp7...  \n",
       "2   4.3 out of 5 stars  https://m.media-amazon.com/images/I/71dujTTJDZ...  \n",
       "3   4.2 out of 5 stars  https://m.media-amazon.com/images/I/71-Su4Wr0H...  \n",
       "4   4.2 out of 5 stars  https://m.media-amazon.com/images/I/81fwKtv0VH...  \n",
       "5   4.2 out of 5 stars  https://m.media-amazon.com/images/I/71sxlhYhKW...  \n",
       "6   4.2 out of 5 stars  https://m.media-amazon.com/images/I/61IhTtJUXJ...  \n",
       "7   4.2 out of 5 stars  https://m.media-amazon.com/images/I/51ZoulFBPG...  \n",
       "8   4.2 out of 5 stars  https://m.media-amazon.com/images/I/51-T19jXch...  \n",
       "9   4.3 out of 5 stars  https://m.media-amazon.com/images/I/71A9Vo1Bat...  \n",
       "10  4.2 out of 5 stars  https://m.media-amazon.com/images/I/61d-phh4Gf...  \n",
       "11  4.2 out of 5 stars  https://m.media-amazon.com/images/I/71dujTTJDZ...  \n",
       "12  4.1 out of 5 stars  https://m.media-amazon.com/images/I/71FPmXaDfb...  \n",
       "13  4.3 out of 5 stars  https://m.media-amazon.com/images/I/51FnmxwFHD...  \n",
       "14  4.2 out of 5 stars  https://m.media-amazon.com/images/I/71U2SiHgbi...  \n",
       "15  4.3 out of 5 stars  https://m.media-amazon.com/images/I/71KCwNV6Mu...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.amazon.in/s?k=Mobile+phones+under+20000&ref=nb_sb_noss_2\"\n",
    "page11 = requests.get(url)\n",
    "#see content in page11\n",
    "soup11 = BeautifulSoup(page11.content)\n",
    "product_name = []  #empty list\n",
    "price = []    #empty list\n",
    "rating = []   #empty list\n",
    "img_url = []   #empty list\n",
    "\n",
    "\n",
    "# Scrape product name\n",
    "for i in soup11.find_all(\"span\",class_=\"a-size-medium a-color-base a-text-normal\"):\n",
    "    product_name.append(i.text)\n",
    "\n",
    "# Scrape product price\n",
    "for i in soup11.find_all(\"span\",class_=\"a-price-whole\"):\n",
    "    price.append(i.text)\n",
    "for i in soup11.find_all(\"span\",class_=\"a-icon-alt\"):\n",
    "    rating.append(i.text)\n",
    "\n",
    "# Scrape images url\n",
    "for i in soup11.find_all(\"img\",class_=\"s-image\"):\n",
    "    img_url.append(i.get(\"src\"))\n",
    "    \n",
    "# Make data frame mobile phones under Rs. 20,000 listed on Amazon.in\n",
    "mobile_phones=pd.DataFrame({})\n",
    "mobile_phones['product_name']=product_name[:16]\n",
    "mobile_phones['price']=price[:16]\n",
    "mobile_phones['Rating']=rating[:16]\n",
    "mobile_phones['img_url'] = img_url[:16]\n",
    "mobile_phones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 8 - local weather from the National \n",
    "Weather Service website of USA, https://www.weather.gov/ for the city, San \n",
    "Francisco. You need to extract data about 7 day extended forecast display for the city. \n",
    "The data should include period, short description, temperature and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Short_description</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overnight</td>\n",
       "      <td>Low: 50 °F</td>\n",
       "      <td>Mostly cloudy</td>\n",
       "      <td>Mostly cloudy, with a low around 50. West sout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>High: 63 °F</td>\n",
       "      <td>Mostly cloudy</td>\n",
       "      <td>Mostly cloudy, then gradually becoming sunny, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thursday Night</td>\n",
       "      <td>Low: 51 °F</td>\n",
       "      <td>Increasing clouds</td>\n",
       "      <td>Increasing clouds, with a low around 51. West ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Friday</td>\n",
       "      <td>High: 64 °F</td>\n",
       "      <td>Cloudy through mid morning</td>\n",
       "      <td>Cloudy through mid morning, then gradual clear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday Night</td>\n",
       "      <td>Low: 51 °F</td>\n",
       "      <td>Patchy drizzle after 2am.  Mostly cloudy</td>\n",
       "      <td>Patchy drizzle after 2am.  Mostly cloudy, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>High: 66 °F</td>\n",
       "      <td>Patchy drizzle before 9am.  Mostly sunny</td>\n",
       "      <td>Patchy drizzle before 9am.  Mostly sunny, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Saturday Night</td>\n",
       "      <td>Low: 51 °F</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>Partly cloudy, with a low around 51.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>High: 65 °F</td>\n",
       "      <td>Mostly sunny</td>\n",
       "      <td>Mostly sunny, with a high near 65.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sunday Night</td>\n",
       "      <td>Low: 52 °F</td>\n",
       "      <td>Partly cloudy</td>\n",
       "      <td>Partly cloudy, with a low around 52.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Period  Temperature                         Short_description  \\\n",
       "0       Overnight   Low: 50 °F                             Mostly cloudy   \n",
       "1        Thursday  High: 63 °F                             Mostly cloudy   \n",
       "2  Thursday Night   Low: 51 °F                         Increasing clouds   \n",
       "3          Friday  High: 64 °F                Cloudy through mid morning   \n",
       "4    Friday Night   Low: 51 °F  Patchy drizzle after 2am.  Mostly cloudy   \n",
       "5        Saturday  High: 66 °F  Patchy drizzle before 9am.  Mostly sunny   \n",
       "6  Saturday Night   Low: 51 °F                             Partly cloudy   \n",
       "7          Sunday  High: 65 °F                              Mostly sunny   \n",
       "8    Sunday Night   Low: 52 °F                             Partly cloudy   \n",
       "\n",
       "                                         Description  \n",
       "0  Mostly cloudy, with a low around 50. West sout...  \n",
       "1  Mostly cloudy, then gradually becoming sunny, ...  \n",
       "2  Increasing clouds, with a low around 51. West ...  \n",
       "3  Cloudy through mid morning, then gradual clear...  \n",
       "4  Patchy drizzle after 2am.  Mostly cloudy, with...  \n",
       "5  Patchy drizzle before 9am.  Mostly sunny, with...  \n",
       "6               Partly cloudy, with a low around 51.  \n",
       "7                 Mostly sunny, with a high near 65.  \n",
       "8               Partly cloudy, with a low around 52.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://forecast.weather.gov/MapClick.php?textField1=37.78&textField2=-122.42#.YJJVsLUzZPY\"\n",
    "page12 = requests.get(url)\n",
    "# see content in page12\n",
    "soup12 = BeautifulSoup(page12.content)\n",
    "period = []  #empty list\n",
    "short_desc = []   #empty list\n",
    "temperature = []   #empty list\n",
    "description = []    #empty list\n",
    "\n",
    "# Scrape period\n",
    "for i in soup12.find_all(\"div\", class_=\"col-sm-2 forecast-label\"):\n",
    "    period.append(i.text)\n",
    "    \n",
    "# Scrape short_desc\n",
    "for i in soup12.find_all('div',class_=\"col-sm-10 forecast-text\"):        \n",
    "        short_desc.append(i.text.split(',')[0])\n",
    "for i in soup12.find_all('div',class_=\"col-sm-10 forecast-text\"):        \n",
    "        description.append(i.text)\n",
    "\n",
    "# Scrape temperature\n",
    "for i in soup12.find_all('p',attrs={'short-desc'}):\n",
    "        if i.next_sibling is not None:\n",
    "            temperature.append(i.next_sibling.text)\n",
    "        else:\n",
    "            temperature.append(' ')\n",
    "\n",
    "# Scrape description\n",
    "for i in soup12.find_all(\"div\", class_=\"col-sm-10 forecast-text\"):\n",
    "        description.append(i.text)\n",
    "# Make data frame\n",
    "san_francisco_weather=pd.DataFrame({})\n",
    "san_francisco_weather['Period']=period[:9]\n",
    "san_francisco_weather['Temperature']=temperature[:9]\n",
    "san_francisco_weather['Short_description']=short_desc[:9]\n",
    "san_francisco_weather['Description']=description[:9]\n",
    "san_francisco_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 9. Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, \n",
    "company name, CTC, and apply date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Titles</th>\n",
       "      <th>Company_Names</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Apply_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior Software Developer</td>\n",
       "      <td>ZoryBoard Software Solutions</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>20 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>SNet Labs Private Limited</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>20 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>RavGins International Private Limited (Wobb.ai)</td>\n",
       "      <td>3.3 - 4 LPA</td>\n",
       "      <td>20 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Operations Executive</td>\n",
       "      <td>TutorBin</td>\n",
       "      <td>3.6 - 3.84 LPA</td>\n",
       "      <td>20 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Associate UI/UX Designer</td>\n",
       "      <td>RavGins International Private Limited (Wobb.ai)</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>20 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Web Development Trainee</td>\n",
       "      <td>Softsensor.ai</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>20 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Square Select Estates</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>19 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vendor Success Manager</td>\n",
       "      <td>Little Olive</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>19 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Full Stack Flutter Developer</td>\n",
       "      <td>HeartShirt</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>19 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Telemarketing Sales Associate</td>\n",
       "      <td>StrategyCo.Global</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>19 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>Labellerr By Tensor Matics Private Limited</td>\n",
       "      <td>7 - 10 LPA</td>\n",
       "      <td>20 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hardware Simulation Engineer</td>\n",
       "      <td>Keysight Technologies</td>\n",
       "      <td>4 - 7 LPA</td>\n",
       "      <td>19 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Education Counselor (Sales)</td>\n",
       "      <td>OpenHouse</td>\n",
       "      <td>3 - 4.5 LPA</td>\n",
       "      <td>18 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Graphic Designer</td>\n",
       "      <td>Cynfas</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>17 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Marketing Analyst</td>\n",
       "      <td>Exhilar Innovative Solutions Private Limited</td>\n",
       "      <td>3 - 6 LPA</td>\n",
       "      <td>17 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mobile App Developer</td>\n",
       "      <td>Wow Labz</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>17 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Software Engineer - AI(NLP)/Front-end(Angular)...</td>\n",
       "      <td>RapidKen.AI</td>\n",
       "      <td>4 - 8 LPA</td>\n",
       "      <td>17 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Corporate Sales Executive</td>\n",
       "      <td>Twin Health</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>17 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Software Tester</td>\n",
       "      <td>Lattice Innovations Private Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>16 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mobile App Developer</td>\n",
       "      <td>Fusion Engineering</td>\n",
       "      <td>4.5 - 5.25 LPA</td>\n",
       "      <td>16 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Junior Backend Developer</td>\n",
       "      <td>VPODS.ai</td>\n",
       "      <td>4 - 5 LPA</td>\n",
       "      <td>16 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Social Media Strategist And Copywriter</td>\n",
       "      <td>Internshala</td>\n",
       "      <td>5 - 6.8 LPA</td>\n",
       "      <td>16 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Junior UI Designer</td>\n",
       "      <td>Phionike Solutions</td>\n",
       "      <td>3.5 - 4 LPA</td>\n",
       "      <td>15 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Customer Service Executive</td>\n",
       "      <td>Verzeo</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>14 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>Erikka India</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>14 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JavaScript Developer</td>\n",
       "      <td>Inflolabs</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>13 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>CrewKarma</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>13 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Business Development Manager (Inside Sales)</td>\n",
       "      <td>Vedic Maths Forum India</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>13 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Proposal &amp; Marketing Engineer</td>\n",
       "      <td>EnWe Clean Technologies Private Limited</td>\n",
       "      <td>3 - 3.25 LPA</td>\n",
       "      <td>12 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Software Engineer Trainee</td>\n",
       "      <td>RightRev India Private Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>12 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>Shashank B</td>\n",
       "      <td>5 - 6 LPA</td>\n",
       "      <td>12 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Office Manager</td>\n",
       "      <td>Wono Inc</td>\n",
       "      <td>5.1 - 6.1 LPA</td>\n",
       "      <td>12 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Wono Inc</td>\n",
       "      <td>5.1 - 6.1 LPA</td>\n",
       "      <td>12 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Administrative Assistant</td>\n",
       "      <td>Wono Inc</td>\n",
       "      <td>5 - 6.5 LPA</td>\n",
       "      <td>12 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Web Developer</td>\n",
       "      <td>Wono Inc</td>\n",
       "      <td>5.5 - 6.5 LPA</td>\n",
       "      <td>12 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Data Entry Associate</td>\n",
       "      <td>Wono Inc</td>\n",
       "      <td>5 - 6.5 LPA</td>\n",
       "      <td>12 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Junior Software Engineer</td>\n",
       "      <td>Byteridge Software Private Limited</td>\n",
       "      <td>3.6 - 4 LPA</td>\n",
       "      <td>11 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Business Development Executive (Inside Sales)</td>\n",
       "      <td>GREedge</td>\n",
       "      <td>3.75 LPA</td>\n",
       "      <td>11 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Client Relationship &amp; Business Development Exe...</td>\n",
       "      <td>Nascent Global Impex LLP</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>11 Jun' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Backend Developer</td>\n",
       "      <td>Reportcard</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>10 Jun' 21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Titles  \\\n",
       "0                          Junior Software Developer    \n",
       "1                       Associate Software Developer    \n",
       "2                               Full Stack Developer    \n",
       "3                               Operations Executive    \n",
       "4                           Associate UI/UX Designer    \n",
       "5                            Web Development Trainee    \n",
       "6                     Business Development Executive    \n",
       "7                             Vendor Success Manager    \n",
       "8                       Full Stack Flutter Developer    \n",
       "9                      Telemarketing Sales Associate    \n",
       "10                      Associate Software Developer    \n",
       "11                      Hardware Simulation Engineer    \n",
       "12                       Education Counselor (Sales)    \n",
       "13                                  Graphic Designer    \n",
       "14                                 Marketing Analyst    \n",
       "15                              Mobile App Developer    \n",
       "16  Software Engineer - AI(NLP)/Front-end(Angular)...   \n",
       "17                         Corporate Sales Executive    \n",
       "18                                   Software Tester    \n",
       "19                              Mobile App Developer    \n",
       "20                          Junior Backend Developer    \n",
       "21            Social Media Strategist And Copywriter    \n",
       "22                                Junior UI Designer    \n",
       "23                        Customer Service Executive    \n",
       "24                    Business Development Associate    \n",
       "25                              JavaScript Developer    \n",
       "26                                 Software Engineer    \n",
       "27       Business Development Manager (Inside Sales)    \n",
       "28                     Proposal & Marketing Engineer    \n",
       "29                         Software Engineer Trainee    \n",
       "30                      Associate Software Developer    \n",
       "31                                    Office Manager    \n",
       "32                               Technical Recruiter    \n",
       "33                          Administrative Assistant    \n",
       "34                                     Web Developer    \n",
       "35                              Data Entry Associate    \n",
       "36                          Junior Software Engineer    \n",
       "37     Business Development Executive (Inside Sales)    \n",
       "38  Client Relationship & Business Development Exe...   \n",
       "39                                 Backend Developer    \n",
       "\n",
       "                                      Company_Names             CTC  \\\n",
       "0                      ZoryBoard Software Solutions       3 - 4 LPA   \n",
       "1                         SNet Labs Private Limited     3 - 3.2 LPA   \n",
       "2   RavGins International Private Limited (Wobb.ai)     3.3 - 4 LPA   \n",
       "3                                          TutorBin  3.6 - 3.84 LPA   \n",
       "4   RavGins International Private Limited (Wobb.ai)       3 - 4 LPA   \n",
       "5                                     Softsensor.ai       3 - 5 LPA   \n",
       "6                             Square Select Estates       3 - 5 LPA   \n",
       "7                                      Little Olive     3 - 3.5 LPA   \n",
       "8                                        HeartShirt     3 - 3.5 LPA   \n",
       "9                                 StrategyCo.Global       3 - 5 LPA   \n",
       "10       Labellerr By Tensor Matics Private Limited      7 - 10 LPA   \n",
       "11                            Keysight Technologies       4 - 7 LPA   \n",
       "12                                        OpenHouse     3 - 4.5 LPA   \n",
       "13                                           Cynfas           3 LPA   \n",
       "14     Exhilar Innovative Solutions Private Limited       3 - 6 LPA   \n",
       "15                                         Wow Labz       3 - 5 LPA   \n",
       "16                                      RapidKen.AI       4 - 8 LPA   \n",
       "17                                      Twin Health       3 - 4 LPA   \n",
       "18              Lattice Innovations Private Limited           3 LPA   \n",
       "19                               Fusion Engineering  4.5 - 5.25 LPA   \n",
       "20                                         VPODS.ai       4 - 5 LPA   \n",
       "21                                      Internshala     5 - 6.8 LPA   \n",
       "22                               Phionike Solutions     3.5 - 4 LPA   \n",
       "23                                           Verzeo           3 LPA   \n",
       "24                                     Erikka India       3 - 5 LPA   \n",
       "25                                        Inflolabs       3 - 5 LPA   \n",
       "26                                        CrewKarma       3 - 5 LPA   \n",
       "27                          Vedic Maths Forum India       3 - 4 LPA   \n",
       "28          EnWe Clean Technologies Private Limited    3 - 3.25 LPA   \n",
       "29                   RightRev India Private Limited           3 LPA   \n",
       "30                                       Shashank B       5 - 6 LPA   \n",
       "31                                         Wono Inc   5.1 - 6.1 LPA   \n",
       "32                                         Wono Inc   5.1 - 6.1 LPA   \n",
       "33                                         Wono Inc     5 - 6.5 LPA   \n",
       "34                                         Wono Inc   5.5 - 6.5 LPA   \n",
       "35                                         Wono Inc     5 - 6.5 LPA   \n",
       "36               Byteridge Software Private Limited     3.6 - 4 LPA   \n",
       "37                                          GREedge        3.75 LPA   \n",
       "38                         Nascent Global Impex LLP       3 - 5 LPA   \n",
       "39                                       Reportcard       3 - 5 LPA   \n",
       "\n",
       "    Apply_Date  \n",
       "0   20 Jun' 21  \n",
       "1   20 Jun' 21  \n",
       "2   20 Jun' 21  \n",
       "3   20 Jun' 21  \n",
       "4   20 Jun' 21  \n",
       "5   20 Jun' 21  \n",
       "6   19 Jun' 21  \n",
       "7   19 Jun' 21  \n",
       "8   19 Jun' 21  \n",
       "9   19 Jun' 21  \n",
       "10  20 Jun' 21  \n",
       "11  19 Jun' 21  \n",
       "12  18 Jun' 21  \n",
       "13  17 Jun' 21  \n",
       "14  17 Jun' 21  \n",
       "15  17 Jun' 21  \n",
       "16  17 Jun' 21  \n",
       "17  17 Jun' 21  \n",
       "18  16 Jun' 21  \n",
       "19  16 Jun' 21  \n",
       "20  16 Jun' 21  \n",
       "21  16 Jun' 21  \n",
       "22  15 Jun' 21  \n",
       "23  14 Jun' 21  \n",
       "24  14 Jun' 21  \n",
       "25  13 Jun' 21  \n",
       "26  13 Jun' 21  \n",
       "27  13 Jun' 21  \n",
       "28  12 Jun' 21  \n",
       "29  12 Jun' 21  \n",
       "30  12 Jun' 21  \n",
       "31  12 Jun' 21  \n",
       "32  12 Jun' 21  \n",
       "33  12 Jun' 21  \n",
       "34  12 Jun' 21  \n",
       "35  12 Jun' 21  \n",
       "36  11 Jun' 21  \n",
       "37  11 Jun' 21  \n",
       "38  11 Jun' 21  \n",
       "39  10 Jun' 21  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://internshala.com/fresher-jobs\"\n",
    "page13 = requests.get(url)\n",
    "# see content in page12\n",
    "soup13 = BeautifulSoup(page13.content)\n",
    "job_titles = []  #empty list\n",
    "company_names = []   #empty list\n",
    "CTC = []   #empty list\n",
    "apply_date = []    #empty list\n",
    "\n",
    "# scrape job title\n",
    "titles=soup13.find_all('div',class_=\"heading_4_5 profile\") \n",
    "for i in titles:\n",
    "    job_titles.append(i.text.replace('\\n', ''))\n",
    "    \n",
    "#scrape company names    \n",
    "companies=soup13.find_all('a',class_=\"link_display_like_text\")\n",
    "for i in companies:\n",
    "    company_names.append(i.text.strip())\n",
    "\n",
    "\n",
    "# scrape ctc and apply date\n",
    "job_info = []\n",
    "info = soup13.find_all(\"div\",class_=\"item_body\")\n",
    "for i in info:\n",
    "    job_info.append(i.text.replace(\"\\n\",\"\").replace(\"\\xa0\",\"\"))\n",
    "    \n",
    "# apply date    \n",
    "for i in range(2,len(job_info),3):\n",
    "    apply_date.append(job_info[i].strip())\n",
    "#CTC    \n",
    "for i in range(1,len(job_info),3):\n",
    "    CTC.append(job_info[i].strip())\n",
    "    \n",
    "# Make data frame\n",
    "JOB=pd.DataFrame({})\n",
    "JOB['Job_Titles']=job_titles\n",
    "JOB['Company_Names']=company_names\n",
    "JOB['CTC']=CTC\n",
    "JOB['Apply_Date']=apply_date\n",
    "JOB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
